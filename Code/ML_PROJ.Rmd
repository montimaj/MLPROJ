---
title: "IST 5535 | Machine Learning Project: New York-Rent Prices-2020-Zillow Dataset"
author: "Group 2 | Tanner Fry, Sayantan Majumdar, Daren Liu"
date: "`r Sys.Date()`"
output: 
  html_document:
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
    echo = TRUE,
    message = FALSE,
    warning = FALSE,
    comment = NA)
```
  
```{r clean, echo=FALSE}
# Clean the environment
rm(list = ls())
```

# Data Exploration

```{r data_explore}
zillow.data <- read.csv('../Data/zillow.csv')
str(zillow.data)
summary(zillow.data)
```

# Data Cleaning

```{r data_cleaning}
zillow.data <- subset(zillow.data, 
                      select = -c(yearBuilt: longitude,
                                  real.estate.provider:commute, latitude,
                                  city, state))
zillow.data <- na.omit(zillow.data)
# there are two rows in the na removed df where price is blank

transform_price <- function(price, sep = ',') {
  library(qdapRegex)
  
  if (price == '' || is.na(price)) {  # Fixes blank issue
    return(NA) 
  }
  price <- paste(price, '/', sep = '')
  check_plus <- ex_between(price, '$', '+')[[1]]
  check_bracket <- ex_between(price, '$', ')')[[1]]
  check_slash <- ex_between(price, '$', '/')[[1]]
  p <- NA
  if (!is.na(check_plus)) {
    p <- as.numeric(gsub(sep, "", check_plus))
  } else if (!is.na(check_bracket)) {
    p <- as.numeric(gsub(sep, "", check_bracket))
  } else if (!is.na(check_slash)) {
    p <- as.numeric(gsub(sep, "", check_slash))
  }
  return(p)
}

zillow.data$price <- sapply(zillow.data$price, transform_price)
hist(zillow.data$price, main = "Histogram of Actual Prices")
# handling outlier, changing the threshold will cause all models to perform poorly
zillow.data$price[zillow.data$price > 1e+6] <- NA
zillow.data <- na.omit(zillow.data)
str(zillow.data)
summary(zillow.data)
write.csv(zillow.data, '../Data/zillow_cleaned.csv', row.names = FALSE)
hist(zillow.data$price, main = "Histogram of Outlier Removed Prices")
```

# Data Exploration V2

```{r data_explore_v2, fig.height=7, fig.width=9}

psych::pairs.panels(zillow.data, 
             method = "pearson", # correlation method 
             hist.col = "green",
             density = TRUE,  # show density plots 
             ellipses = TRUE # show correlation ellipses
             )
```

Price of homes are positively related with the number of bedrooms and bathrooms (at least with most data points via bathrooms. Bathrooms might need to be refined as there seems to be a few outliers).

## Creating Dummies

```{r create_dummies}
zillow.data$homeStatusFOR_SALE <- ifelse(zillow.data$homeStatus ==
                                          'FOR_SALE', 1, 0)
zillow.data$homeStatusOTHER <- ifelse(zillow.data$homeStatus == 'OTHER', 
                                      1, 0)
zillow.data$homeStatusPENDING <- ifelse(zillow.data$homeStatus == 
                                        'PENDING', 1, 0)
zillow.data$homeStatusRECENTLY_SOLD <- ifelse(zillow.data$homeStatus == 
                                              'RECENTLY_SOLD', 1, 0)

zillow.data$homeStatusFOR_RENT <- ifelse(zillow.data$homeStatus ==
                                          'FOR_RENT', 1, 0)

zillow.data$homeTypeCONDO <- ifelse(zillow.data$homeType == 'CONDO', 1, 0)
zillow.data$homeTypeAPARTMENT <- ifelse(zillow.data$homeType ==
                                        'APARTMENT', 1, 0)
zillow.data$homeTypeLOT <- ifelse(zillow.data$homeType == 'LOT', 1, 0)
zillow.data$homeTypeMULTI_FAMILY <- ifelse(zillow.data$homeType ==
                                           'MULTI_FAMILY', 1, 0)
zillow.data$homeTypeSINGLE_FAMILY <- ifelse(zillow.data$homeType ==
                                           'SINGLE_FAMILY', 1, 0)

zillow.data$homeStatus <- NULL
zillow.data$homeType <- NULL
```

## Data Partition
```{r data_partition}
library(caret)
library(parallel)
library(doParallel)

# Required for parallelizing all caret function calls
cl <- makePSOCKcluster(detectCores())
registerDoParallel(cl)

set.seed(0)
# Doing a standard 80%-20% train-test split
zillow.train_index <- createDataPartition(zillow.data$price, p = .8,
                                          list = FALSE)
zillow.train_data <- zillow.data[zillow.train_index,]
zillow.test_data  <- zillow.data[-zillow.train_index,]
plot(zillow.train_data$price)
plot(zillow.test_data$price)
nrow(zillow.train_data)
nrow(zillow.test_data)
```

## Linear Model Selection and Regularization

### Removing Dummies to Resolve Multi-Collinearity

```{r remove_dummies}
zillow.train_data.linear <- zillow.train_data
zillow.test_data.linear <- zillow.test_data
zillow.train_data.linear$homeStatusOTHER <- NULL
zillow.test_data.linear$homeStatusOTHER <- NULL
zillow.train_data.linear$homeTypeLOT <- NULL
zillow.test_data.linear$homeTypeLOT <- NULL
```

### Univariate Feature Selection
```{r uni_feature_select}
zillow.linear.fit <- lm(price ~ ., data = zillow.train_data.linear)
summary(zillow.linear.fit)
print(BIC(zillow.linear.fit))
print(AIC(zillow.linear.fit))
```

### Best Subset Selection
```{r best_subset}
library(leaps)

train_x <- model.matrix(price ~ ., data = zillow.train_data.linear)[,-1]
train_y <- zillow.train_data.linear$price
nv_max <- NULL
fit_best <- regsubsets(x = train_x, y = train_y, nvmax = nv_max)
fit_best_sum <- summary(fit_best)

plot_model_stats <- function(fit_summary) {
  par(mfrow = c(2, 2))

  plot(fit_summary$rss,
       xlab = "Number of Variables",
       ylab = "RSS",
       type = "l")

  plot(fit_summary$adjr2,
       xlab = "Number of Variables",
       ylab = "Adjusted R2",
       type = "l")
  points(which.max(fit_summary$adjr2),
         fit_summary$adjr2[which.max(fit_summary$adjr2)],
         col = "red", cex = 2, pch = 20)
  plot(fit_summary$cp,
       xlab = " Number of Variables",
       ylab = " Cp",
       type = "l")
  points(which.min(fit_summary$cp),
         fit_summary$cp[which.min(fit_summary$cp)],
         col = "red", cex = 2, pch = 20)
  plot(fit_best_sum$bic,
       xlab = " Number of Variables",
       ylab = " BIC",
       type = "l")
  points(which.min(fit_summary$bic),
         fit_summary$bic[which.min(fit_summary$bic)],
         col = "red", cex = 2, pch = 20)
}
plot_model_stats(fit_best_sum)

model_stats <- function(fitted_model, num_var = 5, response = 'price') {
  coefs <- coef(fitted_model, num_var)
  print(coefs)
  var.names <- names(coefs)
  data.subset <- data.frame(train_x[, var.names[-1]])
  data.subset[[response]] <- train_y
  str(data.subset)
}
model_stats(fit_best)
```

### Forward Stepwise Selection
```{r forward_select}
fit_fwd <- regsubsets(x = train_x, y = train_y, nvmax = nv_max,
                      method = 'forward')
fit_fwd_sum <- summary(fit_fwd)
plot_model_stats(fit_fwd_sum)
model_stats(fit_fwd)
```


### Backward Stepwise Selection
```{r backward_select}
fit_bwd <- regsubsets(x = train_x, y = train_y, nvmax = nv_max,
                      method = 'backward')
fit_bwd_sum <- summary(fit_bwd)
plot_model_stats(fit_bwd_sum)
model_stats(fit_bwd)
```

### Lasso
```{r lasso}
library(glmnet)

grid <- 10 ^ seq(10, -2, length = 100)
lasso <- glmnet(x = train_x, y = train_y, alpha = 1, lambda = grid)
plot(lasso, xvar = 'lambda')
#k-folds CV
set.seed(0)
cv_out <- cv.glmnet(train_x, train_y, alpha = 1, lambda = grid,
                    nfolds = 10)
plot(cv_out)
best_lambda <- cv_out$lambda.min
print(best_lambda)
coefs <- predict(lasso, type = "coefficients", s = best_lambda)
print(coefs)
```

### Final Linear Model

```{r final_lm}
zillow.lfit <- lm(price ~ bathrooms + homeStatusFOR_SALE + 
                  homeStatusFOR_RENT, data = zillow.train_data)
summary(zillow.lfit)
print(BIC(zillow.lfit))
print(AIC(zillow.lfit))
plot(zillow.lfit)
```

### Linear Model Evaluation
```{r lm_eval}
library(ggplot2)

zillow.test_pred <- predict(zillow.lfit, newdata = zillow.test_data.linear,
                    interval = "confidence")
eval_df <- cbind(zillow.test_data.linear, zillow.test_pred)
colnames(eval_df)[colnames(eval_df) == "price"] <- "Actual"
colnames(eval_df)[colnames(eval_df) == "fit"] <- "Predicted"
ggplot(eval_df, aes(x = Actual, y = Predicted)) +
    geom_point() +
    geom_line(aes(y = lwr), color = "red", linetype = "dashed")+
    geom_line(aes(y = upr), color = "red", linetype = "dashed")+
    geom_smooth(method = lm, se = TRUE)
postResample(eval_df$Predicted, eval_df$Actual)
plot(eval_df$Predicted, eval_df$Actual)
abline(0, 1)
```

## Regression Tree

```{r rt}
library(tree)

# For non-linear models, we directly use the original dummy containing data
price_rt <- tree(price ~ ., data = zillow.train_data)
plot(price_rt)
text(price_rt, cex = 0.5, col = 'red')
summary(price_rt)
```

### Pruned Regression Tree

```{r prt}
cv_price <- cv.tree(price_rt)
plot(cv_price$size, cv_price$dev, type = 'b', log = 'y',
     xlab = 'Tree Size', ylab = 'Deviance')
```

### Pruned Decision Tree Performance

```{r rt_perform}
rt_yhat <- predict(price_rt, newdata = zillow.test_data)
obs <- zillow.test_data$price
rt_results <- postResample(rt_yhat, obs)
print(rt_results)
plot(rt_yhat, obs)
abline(0, 1)
```

## Random Forest

```{r rf}
library(randomForest)
price_rf <- randomForest(price ~ ., data = zillow.train_data,
                         mtry = 5, importance = TRUE)
price_rf
```

### Optimizing mtry

```{r rf_opt}
num_predictors <- ncol(zillow.train_data) - 1
tuneGrid <- data.frame(mtry = 1: num_predictors)
print(tuneGrid)
control <- trainControl(method = 'repeatedcv',
                        number = 10, repeats = 3)
set.seed(0)
rf_tuned <- train(price ~ ., data = zillow.train_data,
                  method = 'rf',
                  trControl = control,
                  tuneGrid = tuneGrid)
print(rf_tuned)
plot(rf_tuned)
```

### Final RF model

```{r final_rf}
price_rf <- randomForest(price ~ ., data = zillow.train_data,
                         mtry = 12, importance = TRUE)
varImpPlot(price_rf)
```

### Random Forest Performance

```{r rf_perform}
rf_yhat <- predict(price_rf, newdata = zillow.test_data)
rf_results <- postResample(rf_yhat, obs)
print(rf_results)
plot(rf_yhat, obs)
abline(0, 1)
```

## Support Vector Machine

```{r svm}

zillow.train_data.svm <- zillow.train_data
zillow.test_data.svm <- zillow.test_data
zillow.train_data.svm$homeStatusPENDING <- NULL
zillow.test_data.svm$homeStatusPENDING <- NULL
zillow.train_data.svm$homeStatusRECENTLY_SOLD <- NULL
zillow.test_data.svm$homeStatusRECENTLY_SOLD <- NULL
zillow.train_data.svm$homeTypeLOT <- NULL
zillow.test_data.svm$homeTypeLOT <- NULL

svm_cv_caret <- function(data, response, num_folds, repeats, kernel_type) {
  set.seed(0)
  f <- as.formula(paste(response, '~ .'))
  tuneGrid <- data.frame(C = 10 ^ (-2: 2))
  if (kernel_type == 'svmRadial') {
    tuneGrid <- data.frame(C = 10 ^ (-2: 2),
                           sigma = 10 ^ (-2: 2))
  } else if (kernel_type == 'svmPoly') {
    tuneGrid <- data.frame(C = 10 ^ (-2: 2),
                           degree = rep(2, 5),
                           scale = rep(1, 5))
  }
  print(tuneGrid)
  control <- trainControl(method = 'repeatedcv',
                          number = num_folds,
                          repeats = repeats)
  svm_tuned <- train(f, data = data,
                     method = kernel_type,
                     trControl = control,
                     tuneGrid = tuneGrid)
  print(svm_tuned)
  print(svm_tuned$bestTune)
  plot(svm_tuned)
  return(svm_tuned)
}
```

Using 10-fold cross validation to fine tune SVM kernels.

### Linear Kernel

```{r tune_svm_linear}
tune_svm_linear <- svm_cv_caret(zillow.train_data.svm, 'price', 10, 3,
                                'svmLinear')
```

### Radial (RBF) Kernel

```{r tune_svm_radial}
tune_svm_radial <- svm_cv_caret(zillow.train_data.svm, 'price', 10, 3,
                                'svmRadial')
```

### Polynomial Kernel

```{r tune_svm_poly}
tune_svm_poly <- svm_cv_caret(zillow.train_data.svm, 'price', 10, 3,
                              'svmPoly')
```

### Final SVM Model

```{r final_svm}
price_svm <- train(price ~ ., data = zillow.train_data.svm, 
                   method = 'svmPoly',
                   trControl = trainControl(method = "none"), 
                   tuneGrid = data.frame(C = 0.01, degree = 2, scale = 1))
```

### SVM Performance
```{r svm_perform}
svm_yhat <- predict(price_svm, newdata = zillow.test_data.svm)
obs <- zillow.test_data.svm$price
svm_results <- postResample(svm_yhat, obs)
print(svm_results)
plot(svm_yhat, obs)
abline(0, 1)
```

```{r stop_cluster}
stopCluster(cl)
```

